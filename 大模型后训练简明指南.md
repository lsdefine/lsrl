# å¤§æ¨¡å‹åè®­ç»ƒç®€æ˜æŒ‡å—

## åŸºç¡€ï¼šForward-Backward-Step

æ— è®ºä½ æ˜¯åœ¨è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€æŒ‡ä»¤å¾®è°ƒï¼ˆIFTï¼‰ï¼Œè¿˜æ˜¯å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç­–ç•¥è®­ç»ƒï¼Œæ‰€æœ‰çš„æ¨¡å‹è®­ç»ƒæœ¬è´¨ä¸Šéƒ½éµå¾ªåŒä¸€ä¸ªåŸºæœ¬å¾ªç¯ï¼šâ€‹**Forward-Backward-Step**â€‹ã€‚åªæœ‰é€šè¿‡è¿™ä¸‰æ­¥æ‰èƒ½æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

### ä¸‰æ­¥èµ°çš„æœ¬è´¨

#### Forwardï¼ˆå‰å‘ä¼ æ’­ï¼‰

* **è¾“å…¥æ•°æ®**é€šè¿‡æ¨¡å‹å±‚å±‚è®¡ç®—ï¼Œäº§ç”Ÿè¾“å‡º
* è®¡ç®—â€‹**æŸå¤±å‡½æ•°**â€‹ï¼ˆå¦‚äº¤å‰ç†µæŸå¤±ã€ç­–ç•¥æŸå¤±ç­‰ï¼‰
* è¿™ä¸€æ­¥ä¸»è¦æ¶ˆè€—æ˜¾å­˜å­˜å‚¨**æ¿€æ´»å€¼**

#### Backwardï¼ˆåå‘ä¼ æ’­ï¼‰

* ä»æŸå¤±å¼€å§‹ï¼Œé€å±‚è®¡ç®—**æ¢¯åº¦**
* æ¢¯åº¦ä¼šç´¯ç§¯åˆ°å„ä¸ªå‚æ•°ä¸Š
* è¿™ä¸€æ­¥ä¸»è¦æ¶ˆè€—æ˜¾å­˜å­˜å‚¨**æ¢¯åº¦**

#### Stepï¼ˆå‚æ•°æ›´æ–°ï¼‰

* ä½¿ç”¨ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰**æ›´æ–°æ¨¡å‹å‚æ•°**
* å¯èƒ½æ¶‰åŠæ¢¯åº¦è£å‰ªã€å­¦ä¹ ç‡è°ƒåº¦ç­‰
* è¿™ä¸€æ­¥ä¸»è¦æ¶ˆè€—æ˜¾å­˜å­˜å‚¨**ä¼˜åŒ–å™¨çŠ¶æ€**

```python
for batch in dataloader:
	loss = model(batch, labels=batch).loss
	loss.backward()
	opt.step()
```

## èµ„æºè§„åˆ’ï¼šæ˜¾å­˜å ç”¨ä¸æ—¶é—´ä¼°ç®—

é—®é¢˜ï¼šSFTè®­ç»ƒä¸€ä¸ª7B/14Bæ¨¡å‹åˆ°åº•éœ€è¦å¤šå°‘å¼ å¡ï¼Ÿ

### æ¯ä¸€æ­¥éª¤çš„æ˜¾å­˜å ç”¨

é¦–å…ˆï¼Œç›®å‰æˆç†Ÿçš„æ¨¡å‹è®­ç»ƒå‡ä»¥BF16ä¸ºåŸºæœ¬æ ¼å¼ã€‚

BF16ä¸‹ï¼Œä¸€ä¸ª7Bæ¨¡å‹çš„æ¨¡å‹å‚æ•°å ç”¨**14GB**å­˜å‚¨ã€‚

æ¯ä¸€æ­¥çš„æ˜¾å­˜å ç”¨ï¼š

- Forwardï¼šæ¨¡å‹å‚æ•°ï¼ˆ**14GB**ï¼‰ +  å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰
- Backwardï¼šæ¨¡å‹å‚æ•° ï¼ˆ**14GB**ï¼‰+ å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰+ å‚æ•°æ¢¯åº¦ï¼ˆ**14GB**ï¼‰
- Stepï¼šæ¨¡å‹å‚æ•° ï¼ˆ**14GB**ï¼‰+ å‚æ•°æ¢¯åº¦ï¼ˆ**14GB**ï¼‰+ æ¿€æ´»å™¨åŠ¨é‡ï¼ˆ**56GBï¼**ï¼‰
- ç¬¬äºŒæ¬¡Forwardï¼ˆæ¢¯åº¦ç´¯ç§¯ä¸‹ï¼‰ï¼šæ¨¡å‹å‚æ•°ï¼ˆ**14GB**ï¼‰ + å‚æ•°æ¢¯åº¦ï¼ˆ**14GB**ï¼‰+ å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰

æœ€å¤§éœ€è¦å ç”¨84GBæ˜¾å­˜ï¼Œè¶…è¿‡å•å¡80Gã€‚

å¯¹äºä¸€ä¸ª14Bæ¨¡å‹ï¼Œå…¶å‚æ•°å ç”¨**28GB**ã€‚

- Forwardï¼šæ¨¡å‹å‚æ•°ï¼ˆ**28GB**ï¼‰ +  å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰
- Backwardï¼šæ¨¡å‹å‚æ•° ï¼ˆ**28GB**ï¼‰+ å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰+ å‚æ•°æ¢¯åº¦ï¼ˆ**28GB**ï¼‰
- Stepï¼šæ¨¡å‹å‚æ•° ï¼ˆ**28GB**ï¼‰+ å‚æ•°æ¢¯åº¦ï¼ˆ**28GB**ï¼‰+ æ¿€æ´»å™¨åŠ¨é‡ï¼ˆ**112GBï¼**ï¼‰
- ç¬¬äºŒæ¬¡Forwardï¼ˆæ¢¯åº¦ç´¯ç§¯ä¸‹ï¼‰ï¼šæ¨¡å‹å‚æ•°ï¼ˆ**28GB**ï¼‰ + å‚æ•°æ¢¯åº¦ï¼ˆ**28GB**ï¼‰+ å‰å‘æ¿€æ´»å€¼ï¼ˆ**é•¿åº¦ç›¸å…³**ï¼‰

> å¯ä»¥å¼€ä¸ªnvitopå¯¹ç…§ç€çœ‹ï¼Œå¯ä»¥çœ‹åˆ°å·®ä¸å¤šçš„æ˜¾å­˜å ç”¨æƒ…å†µã€‚
> è¿™é‡Œçš„é•¿åº¦ç›¸å…³å®é™…ä¸ŠæŒ‡çš„æ˜¯Batchå¤§å°ç›¸å…³ã€‚1* 8k ~= 2 * 4kï¼Œ etcã€‚ï¼ˆé•¿åº¦åœ¨å‡ kçš„æ—¶å€™attentionçš„äºŒæ¬¡æ–¹å…¶å®ä¸å ä¸»å¯¼åœ°ä½ï¼‰

åœ¨è¿™ä¸€è®¡ç®—ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå³ä½¿æ˜¯7Bæ¨¡å‹åœ¨stepçš„æ—¶å€™ä¹Ÿå®Œå…¨æ— æ³•æ”¾è¿›å•å¼ 80Gæ˜¾å¡ä¸­ã€‚

è€Œæ¨¡å‹è®­ç»ƒèƒ½æ”¯æŒçš„é•¿åº¦ï¼Œåˆ™ç”±å‚æ•°å’Œæ¢¯åº¦ä¹‹å¤–ä½™ä¸‹çš„æ˜¾å­˜ç©ºé—´å†³å®šã€‚

### ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆæ¿€æ´»å™¨åŠ¨é‡ï¼‰

Adamä¼˜åŒ–å™¨éœ€è¦å­˜å‚¨æ¯ä¸ªå‚æ•°çš„momentumå’Œvarianceï¼Œä¸ºå‚æ•°é‡çš„2å€ã€‚

æœ€ä¸ºè‡´å‘½çš„æ˜¯ï¼Œè¿™ä¸¤ä¸ªä¼˜åŒ–å™¨çŠ¶æ€éœ€è¦ä»¥FP32æ ¼å¼å­˜å‚¨ï¼æ‰€ä»¥å­˜å‚¨ç©ºé—´å ç”¨å†æ¬¡ç¿»å€ã€‚

> æ‰€è°“çš„8bit Adamä¹‹ç±»çš„æ–¹æ³•ä¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€ä»¥æ›´ä½ç²¾åº¦è¿›è¡Œå­˜å‚¨ï¼Œå¯ä»¥é¿å…ç¿»å€ã€‚ä½†æ˜¯æ˜¾ç„¶æ®è®¡ç®—è¿˜æ˜¯æ”¾ä¸ä¸‹ã€‚è€Œä¸”ä¼šäº§ç”Ÿç²¾åº¦æŸå¤±ã€‚

### æ¢¯åº¦ç´¯ç§¯

ä¸€èˆ¬æ¥è¯´ï¼Œä¸€ä¸ªæˆç†Ÿçš„å¤§æ¨¡å‹è®­ç»ƒä¸€æ¬¡å‚æ•°æ›´æ–°æ‰€ä½¿ç”¨çš„æ¢¯åº¦ï¼Œè¦æ¥è‡ªäº100ä¸‡ä¸ªï¼ˆç”šè‡³1000ä¸‡ä¸ªï¼‰ä»¥ä¸Šçš„tokensã€‚

è¿™ä¸ªå€¼å®é™…ä¸Šåœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­å‡ ä¹æ˜¯æœ€é‡è¦çš„å‚æ•°ï¼Œä½†æ˜¯å®ƒå¹¶æ²¡æœ‰ä¸€ä¸ªå…¬è®¤çš„åå­—ï¼Œä¸€äº›äººå«å®ƒreal_batch_sizeä»¥å’Œä¼ ç»Ÿçš„batch_sizeåŒºåˆ†ã€‚

å¯ä»¥å¾ˆå®¹æ˜“çš„ä»å®šä¹‰ä¸Šçœ‹åˆ°ï¼Œreal_batch_size = length * batch_size ï¼ˆ* å¡æ•°ï¼‰ã€‚

ä½†æ˜¯å°±ç®—ä¸è€ƒè™‘å…¶ä»–å ç”¨ï¼Œä¹Ÿä¸å¯èƒ½å­˜æ”¾ä¸‹é‚£ä¹ˆå¤šçš„tokenså…³è”çš„å‰å‘æ¿€æ´»å€¼ã€‚

å› æ­¤éœ€è¦æœ‰æ¢¯åº¦ç´¯ç§¯ï¼Œæ„æ€å°±æ˜¯forward-backwardå¾—åˆ°ä¸€ä¸ªBatchå¯¹åº”çš„æ¢¯åº¦ä»¥åï¼Œå®é™…ä¸Šstepä»€ä¹ˆä¹Ÿä¸åšï¼Œåªæ˜¯æŠŠè¿™ä¸ªæ¢¯åº¦ç´¯è®¡èµ·æ¥ã€‚ç›´åˆ°ç´¯è®¡äº†accum_stepsä¸ªBatchäº§ç”Ÿçš„æ¢¯åº¦ä»¥åï¼Œæ‰å°†ç»¼åˆè®¡ç®—çš„æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

å› æ­¤ï¼Œreal_batch_size = length * batch_size * DPå¡æ•° * accum_steps

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œstep()å®é™…ä¸Šæ¯è°ƒç”¨accum_stepsæ¬¡æ‰ä¼šæ›´æ–°ä¸€æ¬¡æ¨¡å‹å‚æ•°ã€‚

> lsrlåŒ…å’Œå¾ˆå¤šæ•™ç¨‹ä¸­çš„é»˜è®¤accum_stepséƒ½è¿‡å°ï¼Œå®é™…ä¸Šå¯ä»¥ä»£å…¥ä¸Šé¢å…¬å¼ç®—ç®—ä¸€èˆ¬éœ€è¦å¤šå¤§çš„accum_stepsæ‰èƒ½æŠŠreal_batch_sizeé¡¶åˆ°100ä¸‡ä»¥ä¸Šã€‚
> 
> æŸäº›æ¡†æ¶å¾ˆé¸¡è´¼åœ°è£…ä½œå®ƒä»¬å¯ä»¥æ”¯æŒä¸Šåƒçš„batch_sizeï¼Œå®é™…ä¸Šå®ƒä»¬å†…éƒ¨ä¹Ÿæ˜¯æ‹†åˆ†ä»¥åè¿›è¡Œaccumulateï¼Œä¸€æ¬¡forwardä¸å¯èƒ½å¡å…¥ä¸Šåƒçš„batch_sizeå¯¹åº”çš„æ¨¡å‹æ¿€æ´»å€¼ã€‚è€Œä¸”å·¨å¤§çš„real_batch_sizeå‡ ä¹æ€»ä¼šå¾—åˆ°æ›´å¥½çš„ç»“æœã€‚
> 
> çœŸå®ä½¿ç”¨è¯·ç”¨å¤§accum_stepsï¼
> 
> çœŸå®ä½¿ç”¨è¯·ç”¨å¤§accum_stepsï¼

### gradient_checkpoint

å¼€å¯gradient_checkpointä»¥åï¼Œå¯ä»¥å¤§å¹…åº¦é™ä½å‰å‘æ¿€æ´»å€¼çš„å­˜å‚¨å ç”¨ã€‚

å…¶åŸç†æ˜¯å°†æœ¬è¯¥å­˜å‚¨çš„æ¿€æ´»å€¼ä¸å­˜å‚¨ï¼Œè€Œæ˜¯åœ¨backwardçš„æ—¶å€™é‡æ–°è®¡ç®—ã€‚

æ˜¾ç„¶å¯ä»¥çœ‹å‡ºï¼Œå®ƒå‡ ä¹éœ€è¦**ç¿»å€**çš„Forwardæ—¶é—´ï¼Œä½†æ˜¯å¯ä»¥å¤§å¹…å‡å°‘**å‰å‘æ¿€æ´»å€¼éƒ¨åˆ†**çš„å­˜å‚¨å ç”¨ã€‚

åœ¨ä¸Šè¿°å­˜å‚¨å ç”¨åˆ†æä¸­ï¼Œå…¶å®å¯ä»¥å‘ç°ç©ºé—´ä¸Šçš„å‹åŠ›æ¯”æ—¶é—´è¦å¤§ã€‚

æ‰€ä»¥ï¼ŒåŸºæœ¬ä¸Šgradient_checkpointå¿…é¡»å¼€å¯ã€‚

ä½†æ˜¯ï¼Œå³ä½¿å¼€å¯äº†gradient_checkpointï¼Œ14Bæ¨¡å‹åœ¨backwardçš„æ—¶å€™ï¼Œ80GBæ˜¾å­˜ä¹Ÿåªå‰©ä¸‹24Gæ˜¾å­˜æ”¾å‰å‘æ¿€æ´»å€¼éƒ¨åˆ†ï¼Œä¹Ÿæ”¾ä¸äº†å¤šé•¿ã€‚

> é‚£ä¹ˆéš¾é“ä¸€å®šè¦å¾ˆå¤šå¼ å¡è¿›è¡Œè®­ç»ƒå—ï¼Ÿ

### æ—¶é—´ç©ºé—´å¹³è¡¡

å¯ä»¥çœ‹åˆ°ä¼˜åŒ–å™¨çŠ¶æ€çš„å­˜å‚¨å ç”¨ç”šè‡³æ¯”æ¨¡å‹æœ¬èº«è¿˜è¦å¤§å¾—å¤šã€‚

æ¨¡å‹çš„è®¡ç®—ï¼ˆforwardå’Œbackwardï¼‰å¿…é¡»ä½¿ç”¨GPUè¿›è¡Œè®¡ç®—ã€‚ä½†æ˜¯ä¼˜åŒ–å™¨å‘¢ï¼Ÿ

> ä¼˜åŒ–å™¨çŠ¶æ€ç›¸å…³çš„è®¡ç®—å‡ ä¹éƒ½æ˜¯é€å…ƒç´ çš„åŠ æ³•ã€ä¹˜æ³•å’Œèµ‹å€¼ã€‚å®é™…ä¸Šå¯¹è®¡ç®—èƒ½åŠ›çš„éœ€æ±‚æ²¡é‚£ä¹ˆé«˜ï¼
> 
> åœ¨è¿™ä¸€è®¾å®šä¸‹ï¼ŒæŠŠä¼˜åŒ–å™¨çŠ¶æ€ä»GPUæ˜¾å­˜ä¸­å‰”é™¤å‡ ä¹æ˜¯æœ€åˆç†çš„é€‰æ‹©ã€‚
> 
> é¡ºå¸¦ä¸€æï¼Œå¦‚æœä½ åœ¨ä½¿ç”¨LLaMA-Factoryæˆ–è€…DeepSpeedç­‰å…¶ä»–æ¡†æ¶çš„æ—¶å€™æ²¡æœ‰æ³¨æ„ä¿å­˜æ¨¡å‹æ—¶çš„è®¾å®šè€Œä¹Ÿä¿å­˜äº†ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œé‚£ä¹ˆå³ä½¿æ˜¯ç¡¬ç›˜ç©ºé—´éƒ½ä¼šé£å¿«åœ°è¢«å·¨å¤§çš„ä¼˜åŒ–å™¨çŠ¶æ€æ¶ˆè€—æ‰ã€‚

### ä¼˜åŒ–å™¨Offload

è§£å†³æ–¹æ¡ˆï¼šå°†æ¨¡å‹å¤åˆ¶ä¸€ä¸ªå‰¯æœ¬æ”¾åœ¨å†…å­˜ä¸­ï¼Œå°†Adamä¼˜åŒ–å™¨ç»‘å®šåœ¨è¿™ä¸ªæ¨¡å‹çš„å†…å­˜å‰¯æœ¬ä¸Šï¼Œè¿™æ ·ä¼˜åŒ–å™¨çŠ¶æ€ä¹Ÿä¼šè‡ªç„¶åœ°äº§ç”Ÿåœ¨å†…å­˜ä¸­ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒForwardå’ŒBackwardä»ç„¶åœ¨GPUä¸­è¿›è¡Œã€‚ä½†æ˜¯åœ¨Stepä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆä»GPUä¸­æ‹·è´ï¼ˆå…¶å®æ˜¯å‰ªåˆ‡ï¼‰æ¢¯åº¦åˆ°å†…å­˜çš„å‰¯æœ¬ä¸­ï¼Œç„¶åä¼˜åŒ–å™¨çš„æ›´æ–°è®¡ç®—å®Œå…¨åœ¨CPUä¸­è¿›è¡Œã€‚

ç›¸æ¯”æ ‡å‡†çš„è®¾è®¡ï¼Œæˆ‘ä»¬äº§ç”Ÿäº†å¦‚ä¸‹æ—¶é—´æˆæœ¬ï¼š

- å°†æ¢¯åº¦æ‹·è´åˆ°å†…å­˜çš„æ—¶é—´
- ä½¿ç”¨CPUè€ŒéGPUè¿›è¡Œæ¨¡å‹æ›´æ–°è®¡ç®—çš„æ—¶é—´
- å°†æ¨¡å‹å‚æ•°æ‹·è´å›GPUçš„æ—¶é—´

è¿™äº›æˆæœ¬ç”¨äºäº¤æ¢**112GB**çš„æ˜¾å­˜å ç”¨ï¼ˆ14Bæ¨¡å‹ä¸‹ï¼‰ï¼Œå®é™…ä¸Šå®Œå…¨åˆ’ç®—ï¼

- åœ¨accumulateçš„è®¾å®šä¸‹ï¼ŒçœŸæ­£çš„å‚æ•°æ›´æ–°ï¼ˆä»¥åŠè¿™äº›é™„åŠ çš„ä¼ è¾“ï¼‰å®é™…ä¸Šæ¯å¾ˆå¤šæ­¥Forward-Backwardæ‰ä¼šçœŸæ­£æ‰§è¡Œä¸€æ¬¡ã€‚
- ä¼˜åŒ–å™¨çš„è®¡ç®—å¤§å¤šéƒ½æ˜¯ç®€å•çš„é€å…ƒç´ è®¡ç®—ï¼Œå®é™…ä¸ŠCPUä¹Ÿä¸æ…¢ã€‚ï¼ˆæ³¨æ„lsrlçš„æç¤ºï¼Œåœ¨å¤šå¡ç¯å¢ƒä¸‹éœ€è¦è®¾ç½®å¥½OMPç¯å¢ƒå˜é‡ï¼‰ã€‚
- CPU-GPUä¼ è¾“ä¼šä½¿ç”¨pinned-memoryï¼Œå®é™…ä¸Šéå¸¸å¿«ï¼ï¼ˆ28GBä¼ è¾“ï¼Œå®æµ‹GPU-CPUéœ€è¦2ç§’ï¼ŒCPU-GPUåªéœ€0.å‡ ç§’ï¼‰
- lsrlå®ç°ä¸­æ²¡æœ‰åœ¨åˆå§‹åŒ–çš„æ—¶å€™pinned-memoryï¼Œè¿™æ ·åˆå§‹åŒ–æ—¶é—´å¤§å¤§å‡å°‘ï¼Œä½†æ˜¯å‰ä¸¤æ¬¡æ‹·è´é€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†æ˜¯ç¬¬ä¸‰æ¬¡æ‹·è´çš„æ—¶å€™torchä¼šè¯†åˆ«åˆ°è‡ªåŠ¨pinnedä¸Šmemoryï¼Œä¹‹åæ•°æ®ä¼ è¾“ä¼šéå¸¸å¿«ã€‚

ç”¨æ³•éå¸¸ç®€å•ï¼šåªéœ€è¦ç”¨lsrlçš„CPUAdamWæ›¿ä»£åŸç”Ÿçš„torch.optim.AdamWå³å¯ã€‚

### grad offload

è§£å†³äº†stepéƒ¨åˆ†çš„ä¼˜åŒ–å™¨æ˜¾å­˜å ç”¨é—®é¢˜ï¼Œè¿˜ä¼šçœ‹åˆ°ä¸€ä¸ªå¥‡æ€ªçš„ç°è±¡ã€‚

> æ¨¡å‹ç¬¬ä¸€æ¬¡forwardå’Œbackwardæ­£å¸¸ã€‚
> 
> å› ä¸ºæœ‰accumulateï¼Œæ‰€ä»¥ç¬¬ä¸€æ¬¡stepå®é™…ä¸Šä»€ä¹ˆä¹Ÿæ²¡åšï¼ˆåªç´¯åŠ äº†æ¢¯åº¦ï¼‰ã€‚
> 
> æ¨¡å‹ç¬¬äºŒæ¬¡forwardç›¸åŒé•¿åº¦çš„æ•°æ®ï¼ŒOOMã€‚

ä»ä¸Šé¢çš„æ˜¾å­˜å ç”¨åˆ†æï¼Œå¯ä»¥éå¸¸å®¹æ˜“åœ°æ‰¾åˆ°è¿™ç§å¥‡æ€ªç°è±¡çš„åŸå› ã€‚

> ç¬¬ä¸€æ¬¡forwardçš„æ—¶å€™ï¼Œparam.grad is Noneã€‚
> 
> ç¬¬äºŒæ¬¡forwardçš„æ—¶å€™ï¼Œå› ä¸ºéœ€è¦ç´¯åŠ æ¢¯åº¦ï¼Œparam.gradæ˜¯ä¸€ä¸ªtensorï¼Œå ç”¨äº†ä¸€å€çš„æ˜¾å­˜ç©ºé—´ã€‚å®é™…ä¸Šç”¨äºå‰å‘æ¿€æ´»å€¼çš„æ˜¾å­˜ç©ºé—´å¤§å¤§å‡å°‘äº†ã€‚

åæ­£åœ¨å†…å­˜ä¸Šå·²ç»æœ‰ä¸€ä¸ªæ¨¡å‹å‚æ•°å’Œæ¢¯åº¦çš„æ‹·è´äº†ï¼Œé‚£ä¹ˆï¼Œå¯ä»¥åœ¨æ¯æ¬¡backwardä»¥åï¼Œéƒ½**ç«‹åˆ»**æŠŠæ¢¯åº¦å‰ªåˆ‡åˆ°å†…å­˜ä¸Šå¹¶è¿›è¡Œç´¯åŠ ï¼Œæ‹·è´å®ŒåæŠŠGPUä¸Šçš„æ¨¡å‹æ¢¯åº¦è®¾ç½®ä¸ºNoneã€‚è¿™æ ·æ¯æ¬¡forwardéƒ½åƒç¬¬ä¸€æ¬¡forwardä¸€æ ·ã€‚

è¿™æ ·æ¯æ¬¡forward-backwardéƒ½éœ€è¦è¿›è¡Œä¸€æ¬¡28GBçš„æ‹·è´ï¼ˆ14Bæ¨¡å‹ä¸‹ï¼‰ï¼Œä½†æ˜¯å¦‚å‰æ‰€è¿°ï¼Œåœ¨pinned-memoryä¸­è¿™ä¸ªæ‹·è´å¾ˆå¿«ã€‚

è€Œæ¢æ¥çš„æ˜¯ï¼Œæ•´æ•´ä¸€å€æ¨¡å‹å ç”¨ç©ºé—´çš„æ˜¾å­˜éƒ½å¯ä»¥ç”¨æ¥æ”¾å‰å‘æ¿€æ´»å€¼ï¼Œåœ¨gradient_checkpointçš„å¸®åŠ©ä¸‹ï¼Œæ”¯æŒé•¿åº¦èƒ½é•¿å¥½å‡ kï¼

> ä¸ºä»€ä¹ˆæˆ‘ä»¬å¯¹forward-backwardä¸€æ¬¡æ”¯æŒçš„é•¿åº¦è¿™ä¹ˆåœ¨æ„ï¼Ÿ
> 
> å› ä¸º**ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§**å¯¹æ¨¡å‹è®­ç»ƒè‡³å…³é‡è¦ã€‚è™½ç„¶æ¢¯åº¦ç´¯ç§¯å¯ä»¥è®©æˆ‘ä»¬ç”¨å°batchè®­ç»ƒï¼Œä½†å¦‚æœå•æ¬¡forwardçš„åºåˆ—é•¿åº¦å¤ªçŸ­ï¼Œä¼šå¸¦æ¥ä¸¤ä¸ªé—®é¢˜ã€‚
> 
> 1. **ç ´åè¯­ä¹‰è¿è´¯æ€§**ï¼šæ¨¡å‹æ— æ³•åœ¨ä¸€ä¸ªå®Œæ•´çš„ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ ï¼Œè¢«è¿«ä»æˆªæ–­çš„ç‰‡æ®µä¸­å­¦ä¹ ï¼Œè¿™ä¼šæŸå®³æ¨¡å‹å¯¹é•¿æ–‡æœ¬çš„ç†è§£èƒ½åŠ›ã€‚åŒæ—¶ï¼Œè®­ç»ƒæ—¶çš„æœ€å¤§é•¿åº¦ä¹Ÿå®šä¹‰äº†æ¨¡å‹åœ¨æ¨ç†æ—¶çš„èƒ½åŠ›ä¸Šé™ã€‚
> 2. **é™ä½è®­ç»ƒæ•ˆç‡**ï¼šæ›´çŸ­çš„åºåˆ—æ„å‘³ç€éœ€è¦æ›´å¤šçš„ç´¯ç§¯æ­¥éª¤æ‰èƒ½è¾¾åˆ°ç›¸åŒçš„real\_batch\_sizeï¼Œè¿™ä¼šå¢åŠ é€šä¿¡å¼€é”€å’Œè®­ç»ƒæ—¶é—´ã€‚

## å¤šå¡ï¼šDPï¼ŒPPä¸TP

> ä¸€ä¸ªå¨å¸ˆç…ä¸€ä¸ªè›‹éœ€è¦1åˆ†é’Ÿï¼Œä¸¤ä¸ªå¨å¸ˆ1åˆ†é’Ÿèƒ½ç…å‡ ä¸ªè›‹ï¼Ÿ
>
> ä¸€ä¸ªå¨å¸ˆè´Ÿè´£ç…æ­£é¢éœ€è¦åŠåˆ†é’Ÿï¼Œå¦ä¸€ä¸ªå¨å¸ˆè´Ÿè´£ç…åé¢ä¹Ÿéœ€è¦åŠåˆ†é’Ÿï¼Œé‚£ä¹ˆä¸¤ä¸ªå¨å¸ˆä¸€èµ·ä¸Šèƒ½æ¯”ä¸€ä¸ªå¨å¸ˆçš„é€Ÿåº¦ç¿»å€å—ï¼Ÿ

åœ¨åˆ†å¸ƒå¼è®¡ç®—ä¸­ï¼Œæœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„åŸç†ï¼šNä¸ªworkerç›¸æ¯”äº1ä¸ªworkerçš„ç†è®ºåŠ é€Ÿæ¯”ä¸Šé™æ˜¯Nå€ï¼Œä½†æ˜¯åŸºæœ¬è¾¾ä¸åˆ°ï¼Œå› ä¸ºè¿˜æœ‰é€šä¿¡å’ŒåŒæ­¥æŸå¤±ã€‚

æç«¯æƒ…å†µä¸‹ï¼ˆä¸åˆç†çš„åˆ†é…ä¸‹ï¼‰ï¼ŒNä¸ªworkerç”šè‡³å¯èƒ½æ¯”1ä¸ªworkeræ›´æ…¢ã€‚ï¼ˆä¸‰ä¸ªå’Œå°šæ²¡æ°´åƒï¼ï¼‰

åœ¨ä½¿ç”¨å¤šå¡æ—¶ï¼Œè¯·ç¡®ä¿ä½ æ¸…æ¥šåœ°çŸ¥é“è¿™äº›å¡éƒ½åœ¨å¹²ä»€ä¹ˆï¼

> å½“çœ‹åˆ°æœ‰äººæŠŠ7Bæ¨¡å‹åˆ‡åˆ†åˆ°4å¼ 80Gå¡ä¸ŠåšçŸ­åºåˆ—æ¨ç†è¿˜æŠ±æ€¨ä¸ºä»€ä¹ˆè¿™ä¹ˆæ…¢ï¼Œæˆ‘åº”è¯¥ç»™ä»–æ‰¹8å¡å—ï¼Ÿ

### DPï¼šData Parallelism

**æ•°æ®å¹¶è¡Œ**æŒ‡çš„æ˜¯ï¼Œæ¯ä¸€å¼ å¡éƒ½æœ‰èƒ½åŠ›å•ç‹¬å¤„ç†ä¸€æ‰¹æ•°æ®ï¼Œè¿™æ ·8å¼ å¡å°±å¯ä»¥åœ¨ç›¸åŒæ—¶é—´å†…å¤„ç†8æ‰¹ä¸åŒçš„æ•°æ®ã€‚

æ¯å¼ å¡éƒ½éœ€è¦å­˜æ”¾ä¸€ä¸ªæ¨¡å‹çš„å‰¯æœ¬ï¼Œå½“æ¨¡å‹å‚æ•°æ›´æ–°æ—¶ï¼Œæ¯å¼ å¡éƒ½éœ€è¦åŒæ­¥æ›´æ–°ä»¥ä¿è¯ä»»æ„æ—¶åˆ»æ¯å¼ å¡ä¸Šçš„æ¨¡å‹å†…å®¹éƒ½ä¸€æ ·ã€‚

å› æ­¤ï¼Œé€šä¿¡åªåœ¨æ¨¡å‹æ›´æ–°æ—¶äº§ç”Ÿï¼Œéœ€è¦åˆ†å‘æ–°çš„æ¨¡å‹å‚æ•°ã€‚æŒ‰ç…§å‰é¢çš„accum_stepsçš„è®¨è®ºï¼Œå¦‚æœå®é™…ä¸Šaccum_stepsè¶³å¤Ÿå¤§ï¼ˆå¦‚256ï¼‰ï¼Œé‚£ä¹ˆæ•°æ®é€šä¿¡çš„é¢‘ç‡éå¸¸ä½ã€‚

è¿˜æœ‰ç­‰å¾…æˆæœ¬ï¼Œå¦‚æœä¸€äº›å¡è·‘çš„æ›´å¿«ï¼Œé‚£ä¹ˆåœ¨æ¨¡å‹æ›´æ–°çš„æ—¶å€™éœ€è¦ç­‰å¾…æœ€æ…¢çš„å¡å®Œæˆå®ƒçš„ä»»åŠ¡ã€‚ä½†æ˜¯åœ¨è¿™ä¹ˆä½çš„åŒæ­¥é¢‘ç‡ä¸‹ï¼Œè¿™ä¸ªæˆæœ¬çš„å æ¯”ä¹Ÿéå¸¸å°ã€‚

æ‰€ä»¥ï¼ŒDPå‡ ä¹èƒ½è¾¾åˆ°Nå€çš„åŠ é€Ÿæ¯”ä¸Šé™ï¼

> å¦‚æœå¼€äº†grad offloadï¼Œé‚£ä¹ˆæ¯æ¬¡forward-backwardéƒ½éœ€è¦æ”¶é›†ä¸€æ¬¡æ¢¯åº¦ï¼Œè™½ç„¶é€šä¿¡æˆæœ¬å¢åŠ äº†ï¼Œä½†æ˜¯ä»ç„¶èƒ½ä¸€æ¬¡å¤„ç†8æ‰¹æ•°æ®ï¼Œä»ç„¶å…·æœ‰ç›¸å½“é«˜çš„åŠ é€Ÿæ¯”ï¼ˆ7.xxå€ï¼‰ã€‚
>
> ä½†æ˜¯å¦‚æœè®­ç»ƒæ•°æ®å˜é•¿å¾ˆä¸¥é‡çš„è¯ï¼Œç­‰å¾…æˆæœ¬å¯èƒ½ä¼šå¢åŠ ã€‚

ç„¶è€Œï¼ŒDPçš„å‰ææ˜¯**æ¯ä¸€å¼ å¡éƒ½æœ‰èƒ½åŠ›å•ç‹¬å¤„ç†ä¸€æ‰¹æ•°æ®**ã€‚æ‰€ä»¥æœ¬æ•™ç¨‹å‰é¢å¯¹äºå•å¡æƒ…å†µè¿›è¡Œäº†å¤§é‡è®¨è®ºã€‚

DPæ˜¯å‡ ä¹èƒ½è¾¾åˆ°Nå€åŠ é€Ÿï¼Œé‚£å¦å¤–ä¸¤ç§æ˜¯ä¸æ˜¯æ›´å¼ºå‘¢ï¼Ÿå¾ˆé—æ†¾ï¼Œå®ƒä»¬ç”šè‡³è¿1å€éƒ½è¾¾ä¸åˆ°ï¼Œä¹Ÿå°±æ˜¯æ¯”å•å¡æ›´æ…¢ã€‚

è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå‰é¢æˆ‘ä»¬è®¨è®ºäº†è¿™ä¹ˆå¤šæ—¶é—´ä¸ç©ºé—´çš„æƒè¡¡ï¼ˆäº‹å®ä¸Šè¿™æ˜¯è®¡ç®—æœºç§‘å­¦çš„æ°¸æ’è¯é¢˜ï¼‰ï¼š
> æ—¶é—´æ…¢ç‚¹å°±æ…¢ç‚¹ï¼Œç©ºé—´è¶…è¿‡äº†å°±æ²¡æ³•è·‘ã€‚
>
> ç©ºé—´èƒ½ç”¨æ»¡å¿…é¡»ç”¨æ»¡ï¼Œæ—¶é—´æœ€å¥½æ²¡æœ‰ä¸€ç‚¹æµªè´¹ã€‚

> å°æç¤ºï¼štorchè¦å¯åŠ¨å¤šå¡ä¸èƒ½ä½¿ç”¨python xx.pyæ¥å¯åŠ¨ï¼Œè€Œè¦ç”¨torchrun --nproc-per-node=N xx.pyæ¥å¯åŠ¨ã€‚æˆ–è€…å…¶ä»–æ¡†æ¶ä¼šå¯¹è¿™ä¸ªåŒ…è£…ä¸€ä¸‹ï¼Œå¦‚deepspeed xx.pyã€‚

### PPï¼šPipeline Parallelism

**æµæ°´çº¿å¹¶è¡Œ**æŒ‡çš„æ˜¯ï¼Œåœ¨ä¸€å¼ å¡æ²¡æœ‰èƒ½åŠ›ä¾›ä¸€ä¸ªæ¨¡å‹å¤„ç†æ•°æ®çš„æ—¶å€™ï¼Œå°†æ¨¡å‹æŒ‰ç…§å±‚åˆ‡åˆ†åˆ°å¤šå¼ å¡ä¸Šï¼ˆæ·±åº¦æ¨¡å‹å°±æ˜¯å¤šå±‚æ¨¡å‹ï¼‰ï¼Œæ¥å…±åŒå¤„ç†ä¸€æ‰¹æ•°æ®ã€‚

å¾ˆæ˜¾ç„¶ï¼Œé¦–å…ˆå®ƒä¸€æ¬¡åªèƒ½å¤„ç†ä¸€æ‰¹æ•°æ®ï¼Œå…¶æ¬¡åœ¨å¤„ç†è¿™æ‰¹æ•°æ®çš„æ—¶å€™ï¼Œæ¯å½“ä¸‹ä¸€å±‚è·¨å¡å°±éœ€è¦è¿›è¡Œé€šä¿¡ã€‚å› æ­¤ï¼Œå…¶æ—¶é—´åŠ é€Ÿæ¯”æ¯”1xè¿˜è¦ä½ã€‚

ä¸€ä¸ªå¥½æ¶ˆæ¯æ˜¯ç°ä»£GPUé€šä¿¡é€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯å†å¿«ä¹Ÿå°±æ˜¯åŠ é€Ÿæ¯”ï¼ˆå®é™…æ˜¯å‡é€Ÿï¼‰æ¥è¿‘äº1ï¼Œå’ŒDPè¿˜æ˜¯å¤©å£¤ä¹‹åˆ«ã€‚

å› æ­¤ï¼ŒPPå®é™…ä¸Šæ˜¯åœ¨**ä¸€å¼ å¡æ²¡æœ‰èƒ½åŠ›ä¾›ä¸€ä¸ªæ¨¡å‹**æ—¶çš„æ— å¥ˆä¹‹ä¸¾ï¼Œè¦æ˜¯å•å¡èƒ½åšåˆ°è‚¯å®šé€‰æ‹©DPã€‚

åœ¨æ¨¡å‹æ›´æ–°çš„æ—¶å€™ï¼Œå› ä¸ºæ¯å¼ å¡ä¸Šæœ‰ä¸€ä¸ªæ¨¡å‹çš„éƒ¨åˆ†ï¼Œå®ƒä»¬å„è‡ªæ›´æ–°è‡ªå·±éƒ¨åˆ†å°±okï¼Œä½†æ˜¯æ­£å¦‚å‰é¢åˆ†æçš„ï¼Œå¤§accum_stepsæƒ…å†µä¸‹ï¼Œæ¨¡å‹æ›´æ–°æ—¶çš„é€šä¿¡å¿½ç•¥ä¸è®¡ä¹Ÿæ— ä¼¤å¤§é›…ã€‚

PPæ˜¯å¦è¶Šå¤šå¡è¶Šå¥½ï¼Ÿæ˜¾ç„¶ä¸æ˜¯ï¼Œæ¨¡å‹åˆ‡çš„è¶Šç¢ï¼Œé€šä¿¡æˆæœ¬è¶Šé«˜ã€‚çœè¶Šå¤šçš„å¡å‡ºæ¥ï¼Œå¯ä»¥è·‘dp+ppã€‚

> æ—¶é—´æ…¢ç‚¹å°±æ…¢ç‚¹ï¼Œç©ºé—´è¶…è¿‡äº†å°±æ²¡æ³•è·‘ã€‚
>
> lsrlä¸­çš„patch_for_multi_gpus.pyç»™å‡ºäº†ä¸€ä¸ªppçš„å®ç°ã€‚

### TPï¼šTensor Parallelism



## RL

æ–½å·¥ä¸­

## ğŸ‘ Citation

If you find this useful, please consider citing our work as follows:

```
@misc{LSRL,
  author = {Jiaqing Liang},
  title = {LSRL: Memory Efficient Large Model Training Framework},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/lsdefine/lsrl}},
}
```
